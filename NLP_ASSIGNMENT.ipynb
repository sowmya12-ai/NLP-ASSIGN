{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9H8de9AWpRDQ",
        "outputId": "6943351c-ebdc-4efc-9b73-c72927cf36fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unigrams:\n",
            "[('natural',), ('language',), ('processing',), ('(',), ('nlp',), (')',), ('is',), ('a',), ('field',), ('of',), ('artificial',), ('intelligence',), ('(',), ('ai',), (')',), ('that',), ('focuses',), ('on',), ('the',), ('interaction',), ('between',), ('computers',), ('and',), ('humans',), ('through',), ('natural',), ('language',), ('.',)]\n",
            "\n",
            "Bigrams:\n",
            "[('natural', 'language'), ('language', 'processing'), ('processing', '('), ('(', 'nlp'), ('nlp', ')'), (')', 'is'), ('is', 'a'), ('a', 'field'), ('field', 'of'), ('of', 'artificial'), ('artificial', 'intelligence'), ('intelligence', '('), ('(', 'ai'), ('ai', ')'), (')', 'that'), ('that', 'focuses'), ('focuses', 'on'), ('on', 'the'), ('the', 'interaction'), ('interaction', 'between'), ('between', 'computers'), ('computers', 'and'), ('and', 'humans'), ('humans', 'through'), ('through', 'natural'), ('natural', 'language'), ('language', '.')]\n",
            "\n",
            "Trigrams:\n",
            "[('natural', 'language', 'processing'), ('language', 'processing', '('), ('processing', '(', 'nlp'), ('(', 'nlp', ')'), ('nlp', ')', 'is'), (')', 'is', 'a'), ('is', 'a', 'field'), ('a', 'field', 'of'), ('field', 'of', 'artificial'), ('of', 'artificial', 'intelligence'), ('artificial', 'intelligence', '('), ('intelligence', '(', 'ai'), ('(', 'ai', ')'), ('ai', ')', 'that'), (')', 'that', 'focuses'), ('that', 'focuses', 'on'), ('focuses', 'on', 'the'), ('on', 'the', 'interaction'), ('the', 'interaction', 'between'), ('interaction', 'between', 'computers'), ('between', 'computers', 'and'), ('computers', 'and', 'humans'), ('and', 'humans', 'through'), ('humans', 'through', 'natural'), ('through', 'natural', 'language'), ('natural', 'language', '.')]\n",
            "\n",
            "Bigram Probabilities:\n",
            "('natural', 'language'): 1.0000\n",
            "('language', 'processing'): 0.5000\n",
            "('processing', '('): 1.0000\n",
            "('(', 'nlp'): 0.5000\n",
            "('nlp', ')'): 1.0000\n",
            "(')', 'is'): 0.5000\n",
            "('is', 'a'): 1.0000\n",
            "('a', 'field'): 1.0000\n",
            "('field', 'of'): 1.0000\n",
            "('of', 'artificial'): 1.0000\n",
            "('artificial', 'intelligence'): 1.0000\n",
            "('intelligence', '('): 1.0000\n",
            "('(', 'ai'): 0.5000\n",
            "('ai', ')'): 1.0000\n",
            "(')', 'that'): 0.5000\n",
            "('that', 'focuses'): 1.0000\n",
            "('focuses', 'on'): 1.0000\n",
            "('on', 'the'): 1.0000\n",
            "('the', 'interaction'): 1.0000\n",
            "('interaction', 'between'): 1.0000\n",
            "('between', 'computers'): 1.0000\n",
            "('computers', 'and'): 1.0000\n",
            "('and', 'humans'): 1.0000\n",
            "('humans', 'through'): 1.0000\n",
            "('through', 'natural'): 1.0000\n",
            "('language', '.'): 0.5000\n",
            "\n",
            "Next word prediction for 'the':\n",
            "interaction: 1\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk import bigrams, trigrams, FreqDist\n",
        "from nltk.util import ngrams\n",
        "from nltk.tokenize import word_tokenize\n",
        "from collections import defaultdict, Counter\n",
        "import random\n",
        "\n",
        "# Ensure necessary NLTK data is downloaded\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Sample text corpus\n",
        "text = \"Natural language processing (NLP) is a field of artificial intelligence (AI) that focuses on the interaction between computers and humans through natural language.\"\n",
        "\n",
        "# Tokenize the text\n",
        "tokens = word_tokenize(text.lower())\n",
        "\n",
        "# Unigrams\n",
        "unigrams = list(nltk.ngrams(tokens, 1))\n",
        "print(\"Unigrams:\")\n",
        "print(unigrams)\n",
        "\n",
        "# Bigrams\n",
        "bigrams_list = list(nltk.ngrams(tokens, 2))\n",
        "print(\"\\nBigrams:\")\n",
        "print(bigrams_list)\n",
        "\n",
        "# Trigrams\n",
        "trigrams_list = list(nltk.ngrams(tokens, 3))\n",
        "print(\"\\nTrigrams:\")\n",
        "print(trigrams_list)\n",
        "\n",
        "# Bigram probabilities\n",
        "bigram_freq = FreqDist(bigrams_list)\n",
        "unigram_freq = FreqDist(tokens)\n",
        "bigram_prob = {bigram: bigram_freq[bigram] / unigram_freq[bigram[0]] for bigram in bigram_freq}\n",
        "\n",
        "print(\"\\nBigram Probabilities:\")\n",
        "for bigram, prob in bigram_prob.items():\n",
        "    print(f\"{bigram}: {prob:.4f}\")\n",
        "\n",
        "# Next word prediction\n",
        "def predict_next_word(word, bigram_prob, top_n=1):\n",
        "    next_words = [bigram[1] for bigram in bigram_prob if bigram[0] == word]\n",
        "    if not next_words:\n",
        "        return []\n",
        "    next_word_freq = Counter(next_words)\n",
        "    return next_word_freq.most_common(top_n)\n",
        "\n",
        "word = 'the'\n",
        "print(f\"\\nNext word prediction for '{word}':\")\n",
        "predictions = predict_next_word(word, bigram_prob)\n",
        "for prediction, freq in predictions:\n",
        "    print(f\"{prediction}: {freq}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LMY98CLsqr37"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}